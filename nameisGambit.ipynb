{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e46c69-03e6-4e6b-ab23-8f4ced72c587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset, random_split\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Custom dataset class to handle our data\n",
    "class CustomTextDataset(TorchDataset):\n",
    "    def __init__(self, texts, tokenizer, block_size=128):\n",
    "        self.examples = []\n",
    "        for text in texts:\n",
    "            tokenized_text = tokenizer(text, truncation=True, max_length=block_size, padding=\"max_length\")\n",
    "            self.examples.append(tokenized_text)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {key: torch.tensor(val) for key, val in self.examples[i].items()}\n",
    "\n",
    "# Load and preprocess dataset\n",
    "def load_and_preprocess_dataset(file_path, tokenizer, block_size=128):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['text'] = df['madde'].astype(str) + \": \" + df['anlam'].astype(str)\n",
    "    \n",
    "    # Filter texts with length >= 15 words\n",
    "    df = df[df['text'].apply(lambda x: len(x.split()) >= 15)]\n",
    "    \n",
    "    texts = df['text'].tolist()\n",
    "    print(len(texts))\n",
    "    return CustomTextDataset(texts, tokenizer, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20463826-e3d5-4135-aec6-e00042063176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7870\n"
     ]
    }
   ],
   "source": [
    "# Paths and configurations\n",
    "train_file_path = \"tdk_word_meaning_data.csv\"  # Update with your CSV file path\n",
    "model_name = r\"C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer\"\n",
    "output_dir = r\"C:\\Users\\STJ\\Desktop\\results2\"\n",
    "overwrite_output_dir = True\n",
    "per_device_train_batch_size = 8\n",
    "num_train_epochs = 3\n",
    "save_steps = 10\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Add pad token\n",
    "special_tokens = {'pad_token': '<PAD>'}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_and_preprocess_dataset(train_file_path, tokenizer)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0b733e0-bcf2-41ff-b158-fc290cb6a526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12613, 14613,    26, 10627, 17154,   423,   820,    12,  4408,   345,\n",
       "        10202,    12,  4551,   736,  2635,   294, 13325,  1142,    12,  2544,\n",
       "         5530,   960,  6173,   591,  2416, 50257, 50257, 50257, 50257, 50257,\n",
       "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55e9d65f-eeae-4d53-b1f0-349eefef693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\tuners\\lora\\layer.py:1119: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2361' max='2361' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2361/2361 2:30:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.378800</td>\n",
       "      <td>4.064568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.097500</td>\n",
       "      <td>3.968937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.163200</td>\n",
       "      <td>3.914739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.100500</td>\n",
       "      <td>3.880788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.092600</td>\n",
       "      <td>3.851108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.979700</td>\n",
       "      <td>3.833823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.128600</td>\n",
       "      <td>3.815324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.166000</td>\n",
       "      <td>3.803720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.120500</td>\n",
       "      <td>3.795265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.053500</td>\n",
       "      <td>3.787807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>4.035100</td>\n",
       "      <td>3.781930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.004000</td>\n",
       "      <td>3.777242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.835700</td>\n",
       "      <td>3.768749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>4.018400</td>\n",
       "      <td>3.765258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.981700</td>\n",
       "      <td>3.761401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.917000</td>\n",
       "      <td>3.758225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>3.999000</td>\n",
       "      <td>3.755078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>3.911100</td>\n",
       "      <td>3.753883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>3.925100</td>\n",
       "      <td>3.751397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.973600</td>\n",
       "      <td>3.748749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>3.958300</td>\n",
       "      <td>3.747601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>4.013900</td>\n",
       "      <td>3.746385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>3.865600</td>\n",
       "      <td>3.746107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STJ\\anaconda3\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Apply LoRA\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    inference_mode=False, \n",
    "    r     =8, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    save_steps=save_steps,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,  # Use mixed precision (fp16) if supported by the hardware for faster training\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "trainer.save_model(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a7824d8-538e-46b6-a498-1a5c116a5217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing file: C:\\Users\\Dell\\OneDrive\\MasaÃ¼stÃ¼\\FineTunedModel\\config.json\n",
      "Missing file: C:\\Users\\Dell\\OneDrive\\MasaÃ¼stÃ¼\\FineTunedModel\\special_tokens_map.json\n",
      "Missing file: C:\\Users\\Dell\\OneDrive\\MasaÃ¼stÃ¼\\FineTunedModel\\tokenizer_config.json\n",
      "Missing file: C:\\Users\\Dell\\OneDrive\\MasaÃ¼stÃ¼\\FineTunedModel\\vocab.json\n",
      "Missing file: C:\\Users\\Dell\\OneDrive\\MasaÃ¼stÃ¼\\FineTunedModel\\merges.txt\n",
      "Missing file: C:\\Users\\Dell\\OneDrive\\MasaÃ¼stÃ¼\\FineTunedModel\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_path = r\"C:\\Users\\Dell\\OneDrive\\MasaÃ¼stÃ¼\\FineTunedModel\"\n",
    "\n",
    "# Check if all necessary files exist\n",
    "required_files = [\"config.json\", \"special_tokens_map.json\", \"tokenizer_config.json\", \"vocab.json\", \"merges.txt\", \"pytorch_model.bin\"]\n",
    "for file_name in required_files:\n",
    "    file_path = os.path.join(model_path, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"Missing file: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb21778a-2e7e-4a54-bb96-de88c01e2872",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Impossible to guess which tokenizer to use. Please provide a PreTrainedTokenizer class or a path/identifier to a pretrained tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m GPT2LMHeadModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Pipeline oluÅŸturma\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m text_generator \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Ã–rnek bir kelimenin anlamÄ±nÄ± bulma\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_word_meaning\u001b[39m(word, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:977\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m         tokenizer \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    976\u001b[0m         \u001b[38;5;66;03m# Impossible to guess what is the right tokenizer here\u001b[39;00m\n\u001b[1;32m--> 977\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    978\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImpossible to guess which tokenizer to use. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    979\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide a PreTrainedTokenizer class or a path/identifier to a pretrained tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    980\u001b[0m         )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;66;03m# Instantiate tokenizer if needed\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tokenizer, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[1;31mException\u001b[0m: Impossible to guess which tokenizer to use. Please provide a PreTrainedTokenizer class or a path/identifier to a pretrained tokenizer."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Model ve tokenizer'Ä± yÃ¼kleyin\n",
    "model_path = r\"C:\\Users\\STJ\\Desktop\\results2\"  # Fine-tuned modelin kaydedildiÄŸi yol\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "\n",
    "# Pipeline oluÅŸturma\n",
    "text_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Ã–rnek bir kelimenin anlamÄ±nÄ± bulma\n",
    "def get_word_meaning(word, max_length=50):\n",
    "    prompt = word + \":\"\n",
    "    generated_texts = text_generator(prompt, max_length=max_length, num_return_sequences=1)\n",
    "    meaning = generated_texts[0]['generated_text'][len(prompt):].strip()\n",
    "    return meaning\n",
    "\n",
    "# Kelimenin anlamÄ±nÄ± almak iÃ§in Ã¶rnek kullanÄ±m\n",
    "word = \"uyumak nedemek \"\n",
    "meaning = get_word_meaning(word)\n",
    "print(f\"{word}: {meaning}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b51415a0-f79f-4ddd-9ec1-bec227b5bfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ''}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "from transformers import pipeline\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(r\"C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(r\"C:\\Users\\STJ\\Desktop\\final_model_and_tokenizer\")\n",
    "\n",
    "text_generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "r = text_generator(\"Teknolojinin geliÅŸimi hayatÄ±mÄ±zÄ± Ã¶nemli Ã¶lÃ§Ã¼de etkiledi. \", max_length=100)\n",
    "[{'generated_text': \"\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0779c8b7-a4c2-42f8-8ba3-f06eb13476eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Teknolojinin geliÅŸimi hayatÄ±mÄ±zÄ± Ã¶nemli Ã¶lÃ§Ã¼de etkiledi. \"Teknoloji\" deyince aklÄ±mÄ±za ilk etapta makineler geliyor. Ã–rneÄŸin, televizyon gibi yeni bir teknoloji olan televizyonun mucidi James Cromwell, \"dijital televizyonun dijital gÃ¶rÃ¼ntÃ¼ olarak bir televizyonun bir fotoÄŸrafÄ±nÄ±n aynÄ± anda iki fotoÄŸrafÄ± olarak kullanÄ±labileceÄŸini sÃ¶ylemiÅŸti. Son olarak yine James Cromwell, TV ekranÄ±yla ilgili bir makale yazmâ€¦ DevamÄ±nÄ± oku..\\nDevamÄ± iÃ§in tÄ±klayÄ±nÄ±z. Televizyonla Ä°lgili Kompozisyon\\nDevamÄ± iÃ§in tÄ±klayÄ±nÄ±z. Yeni Teknolojiyi KeÅŸ'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904e88c-fc86-4e97-a386-de948c5f72a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset, random_split\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Custom dataset class to handle our data\n",
    "class CustomTextDataset(TorchDataset):\n",
    "    def __init__(self, texts, tokenizer, block_size=128):\n",
    "        self.examples = []\n",
    "        for text in texts:\n",
    "            tokenized_text = tokenizer(text, truncation=True, max_length=block_size, padding=\"max_length\")\n",
    "            self.examples.append(tokenized_text)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {key: torch.tensor(val) for key, val in self.examples[i].items()}\n",
    "\n",
    "# Load and preprocess dataset\n",
    "def load_and_preprocess_dataset(file_path, tokenizer, block_size=128):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['text'] = \"Kelime: \" + df['madde'].astype(str) + \". Anlam: \" + df['anlam'].astype(str)\n",
    "    \n",
    "    # Filter texts with length >= 15 words\n",
    "    df = df[df['text'].apply(lambda x: len(x.split()) >= 6)]\n",
    "    \n",
    "    texts = df['text'].tolist()\n",
    "    print(len(texts))\n",
    "    return CustomTextDataset(texts, tokenizer, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c810691-4bbd-4be7-915a-aad6f5c5a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and configurations\n",
    "train_file_path = \"tdk_word_meaning_data.csv\"  # Update with your CSV file path\n",
    "model_name = \"turkish-gpt2\"\n",
    "output_dir = \"results4\"\n",
    "overwrite_output_dir = True\n",
    "per_device_train_batch_size = 8\n",
    "num_train_epochs = 3\n",
    "save_steps = 10\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Add pad token\n",
    "special_tokens = {'pad_token': '<PAD>'}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_and_preprocess_dataset(train_file_path, tokenizer)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d7dfd8-6128-4407-9a51-0ccd653e9692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling, TrainerCallback\n",
    "from transformers import LoraConfig, TaskType\n",
    "\n",
    "# Prepare data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Apply LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    save_steps=save_steps,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,  # Use mixed precision (fp16) if supported by the hardware for faster training\n",
    ")\n",
    "\n",
    "# Custom callback for better fine-tuning control\n",
    "class CustomCallback(TrainerCallback):\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        print(\"Starting training...\")\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        print(f\"Epoch {state.epoch} completed.\")\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        print(\"Training finished.\")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    callbacks=[CustomCallback()]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205cfc19-2a78-4d49-8aed-50cfcc1d5695",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install peft\n",
    "\n",
    "!git clone https://huggingface.co/ytu-ce-cosmos/turkish-gpt2\n",
    "\n",
    "%cd turkish-gpt2\n",
    "\n",
    "!ls\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "!ls\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset, random_split\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Custom dataset class to handle our data\n",
    "class CustomTextDataset(TorchDataset):\n",
    "    def __init__(self, texts, tokenizer, block_size=128):\n",
    "        self.examples = []\n",
    "        for text in texts:\n",
    "            tokenized_text = tokenizer(text, truncation=True, max_length=block_size, padding=\"max_length\")\n",
    "            self.examples.append(tokenized_text)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {key: torch.tensor(val) for key, val in self.examples[i].items()}\n",
    "\n",
    "# Load and preprocess dataset\n",
    "def load_and_preprocess_dataset(file_path, tokenizer, block_size=128):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['text'] = \"Kelime: \" + df['madde'].astype(str) + \". Anlam: \" + df['anlam'].astype(str)\n",
    "    \n",
    "    # Filter texts with length >= 15 words\n",
    "    df = df[df['text'].apply(lambda x: len(x.split()) >= 6)]\n",
    "    \n",
    "    texts = df['text'].tolist()\n",
    "    print(len(texts))\n",
    "    return CustomTextDataset(texts, tokenizer, block_size)\n",
    "\n",
    "# Paths and configurations\n",
    "train_file_path = \"/content/tdk_word_meaning_data.csv\"  # Update with your CSV file path\n",
    "model_name = \"/content/turkish-gpt2\"\n",
    "output_dir = \"results4\"\n",
    "overwrite_output_dir = True\n",
    "per_device_train_batch_size = 8\n",
    "num_train_epochs = 3\n",
    "save_steps = 10\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Add pad token\n",
    "special_tokens = {'pad_token': '<PAD>'}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_and_preprocess_dataset(train_file_path, tokenizer)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling, TrainerCallback\n",
    "from peft import LoraConfig, TaskType\n",
    "\n",
    "# Prepare data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Apply LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    save_steps=save_steps,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,  # Use mixed precision (fp16) if supported by the hardware for faster training\n",
    ")\n",
    "\n",
    "# Custom callback for better fine-tuning control\n",
    "class CustomCallback(TrainerCallback):\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        print(\"Starting training...\")\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        print(f\"Epoch {state.epoch} completed.\")\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        print(\"Training finished.\")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    callbacks=[CustomCallback()]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "!pip install --upgrade transformers\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
